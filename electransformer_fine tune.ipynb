{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, LayerNormalization, Dropout, Input, MultiHeadAttention\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from captum.attr import GradientShap\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder as le, MinMaxScaler as MM\n",
    "from pycaret.regression import *\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "from scipy.stats import randint as sp_randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "data = pd.read_excel('/Users/gim-yeon-u/Desktop/Sejong Univ/2024-1/캡스톤/통합 문서4.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Min</th>\n",
       "      <th>Room</th>\n",
       "      <th>Electricity_Usage_kWh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28.268832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.498430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25.954633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15.041049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10.570874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048569</th>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>71.076569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>103.324872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>83.785497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>17.334466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>58.837745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048574 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Month  Day  Hour  Min  Room  Electricity_Usage_kWh\n",
       "0            3    1     0    0     1              28.268832\n",
       "1            3    1     0    1     1              16.498430\n",
       "2            3    1     0    2     1              25.954633\n",
       "3            3    1     0    3     1              15.041049\n",
       "4            3    1     0    4     1              10.570874\n",
       "...        ...  ...   ...  ...   ...                    ...\n",
       "1048569      5   26     4    9     4              71.076569\n",
       "1048570      5   26     4   10     4             103.324872\n",
       "1048571      5   26     4   11     4              83.785497\n",
       "1048572      5   26     4   12     4              17.334466\n",
       "1048573      5   26     4   13     4              58.837745\n",
       "\n",
       "[1048574 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('elecdummy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 0.2428, Validation Loss: 0.2404\n",
      "Epoch 2, Training Loss: 0.2417, Validation Loss: 0.2400\n",
      "Epoch 3, Training Loss: 0.2404, Validation Loss: 0.2369\n",
      "Epoch 4, Training Loss: 0.2381, Validation Loss: 0.2369\n",
      "Epoch 5, Training Loss: 0.2365, Validation Loss: 0.2342\n",
      "Epoch 6, Training Loss: 0.2342, Validation Loss: 0.2316\n",
      "Epoch 7, Training Loss: 0.2324, Validation Loss: 0.2294\n",
      "Epoch 8, Training Loss: 0.2309, Validation Loss: 0.2270\n",
      "Epoch 9, Training Loss: 0.2296, Validation Loss: 0.2255\n",
      "Epoch 10, Training Loss: 0.2286, Validation Loss: 0.2246\n",
      "Epoch 11, Training Loss: 0.2273, Validation Loss: 0.2255\n",
      "Epoch 12, Training Loss: 0.2264, Validation Loss: 0.2225\n",
      "Epoch 13, Training Loss: 0.2255, Validation Loss: 0.2214\n",
      "Epoch 14, Training Loss: 0.2247, Validation Loss: 0.2212\n",
      "Epoch 15, Training Loss: 0.2237, Validation Loss: 0.2224\n",
      "Epoch 16, Training Loss: 0.2230, Validation Loss: 0.2223\n",
      "Epoch 17, Training Loss: 0.2222, Validation Loss: 0.2181\n",
      "Epoch 18, Training Loss: 0.2212, Validation Loss: 0.2172\n",
      "Epoch 19, Training Loss: 0.2203, Validation Loss: 0.2152\n",
      "Epoch 20, Training Loss: 0.2197, Validation Loss: 0.2147\n",
      "Epoch 21, Training Loss: 0.2187, Validation Loss: 0.2145\n",
      "Epoch 22, Training Loss: 0.2180, Validation Loss: 0.2165\n",
      "Epoch 23, Training Loss: 0.2176, Validation Loss: 0.2107\n",
      "Epoch 24, Training Loss: 0.2169, Validation Loss: 0.2182\n",
      "Epoch 25, Training Loss: 0.2163, Validation Loss: 0.2129\n",
      "Epoch 26, Training Loss: 0.2159, Validation Loss: 0.2112\n",
      "Epoch 27, Training Loss: 0.2156, Validation Loss: 0.2102\n",
      "Epoch 28, Training Loss: 0.2152, Validation Loss: 0.2096\n",
      "Epoch 29, Training Loss: 0.2148, Validation Loss: 0.2078\n",
      "Epoch 30, Training Loss: 0.2144, Validation Loss: 0.2104\n",
      "Epoch 31, Training Loss: 0.2140, Validation Loss: 0.2096\n",
      "Epoch 32, Training Loss: 0.2137, Validation Loss: 0.2071\n",
      "Epoch 33, Training Loss: 0.2132, Validation Loss: 0.2065\n",
      "Epoch 34, Training Loss: 0.2128, Validation Loss: 0.2065\n",
      "Epoch 35, Training Loss: 0.2128, Validation Loss: 0.2072\n",
      "Epoch 36, Training Loss: 0.2122, Validation Loss: 0.2062\n",
      "Epoch 37, Training Loss: 0.2118, Validation Loss: 0.2052\n",
      "Epoch 38, Training Loss: 0.2116, Validation Loss: 0.2048\n",
      "Epoch 39, Training Loss: 0.2111, Validation Loss: 0.2043\n",
      "Epoch 40, Training Loss: 0.2109, Validation Loss: 0.2044\n",
      "Epoch 41, Training Loss: 0.2106, Validation Loss: 0.2048\n",
      "Epoch 42, Training Loss: 0.2105, Validation Loss: 0.2038\n",
      "Epoch 43, Training Loss: 0.2102, Validation Loss: 0.2063\n",
      "Epoch 44, Training Loss: 0.2100, Validation Loss: 0.2069\n",
      "Epoch 45, Training Loss: 0.2095, Validation Loss: 0.2034\n",
      "Epoch 46, Training Loss: 0.2094, Validation Loss: 0.2032\n",
      "Epoch 47, Training Loss: 0.2091, Validation Loss: 0.2029\n",
      "Epoch 48, Training Loss: 0.2090, Validation Loss: 0.2019\n",
      "Epoch 49, Training Loss: 0.2087, Validation Loss: 0.2034\n",
      "Epoch 50, Training Loss: 0.2084, Validation Loss: 0.2014\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target = 'Electricity_Usage_kWh'\n",
    "\n",
    "\n",
    "X = data.drop(target, axis=1).values\n",
    "y = data[target].values.reshape(-1, 1)\n",
    "\n",
    "\n",
    "scaler_X = RobustScaler()\n",
    "scaler_y = RobustScaler()\n",
    "\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.FloatTensor(y_test)\n",
    "\n",
    "\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, model_dim, num_heads, num_encoder_layers, num_decoder_layers, output_dim):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.input_linear = nn.Linear(input_dim, model_dim)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=model_dim,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers\n",
    "        )\n",
    "        self.output_linear = nn.Linear(model_dim, output_dim)\n",
    "    \n",
    "    def forward(self, src):\n",
    "        src = src.unsqueeze(1)\n",
    "        src = self.input_linear(src)\n",
    "        src = src.permute(1, 0, 2)\n",
    "        output = self.transformer.encoder(src)\n",
    "        output = self.output_linear(output.permute(1, 0, 2).squeeze(1))\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "model = TransformerModel(input_dim=5, model_dim=128, num_heads=2, num_encoder_layers=2, num_decoder_layers=2, output_dim=1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
    "criterion = nn.SmoothL1Loss()\n",
    "\n",
    "\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch_x)\n",
    "        loss = criterion(predictions, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_predictions = model(X_test_tensor)\n",
    "        val_loss = criterion(val_predictions, y_test_tensor)\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Training Loss: {avg_loss:.4f}, Validation Loss: {val_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_original_tensor = torch.FloatTensor(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions_tensor = model(X_original_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = scaler_y.inverse_transform(predictions_tensor.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.466539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.464962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.463379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.461800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.460224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048569</th>\n",
       "      <td>61.520790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>61.613380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>61.705940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>61.798519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>61.891083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048574 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "0        17.466539\n",
       "1        17.464962\n",
       "2        17.463379\n",
       "3        17.461800\n",
       "4        17.460224\n",
       "...            ...\n",
       "1048569  61.520790\n",
       "1048570  61.613380\n",
       "1048571  61.705940\n",
       "1048572  61.798519\n",
       "1048573  61.891083\n",
       "\n",
       "[1048574 rows x 1 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_excel = pd.DataFrame(predictions)\n",
    "predict_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_excel.to_excel('elecprotoresult3.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, 'elecmodelprotorobustfinal2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Values: [[-0.19892891]\n",
      " [-0.19896285]\n",
      " [-0.19899628]\n",
      " ...\n",
      " [-0.26800784]\n",
      " [-0.26801014]\n",
      " [-0.26801175]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "\n",
    "data_path = '/Users/gim-yeon-u/Desktop/Sejong Univ/2024-1/캡스톤/elecdummyvalidation.xlsx'\n",
    "data = pd.read_excel(data_path)\n",
    "\n",
    "\n",
    "X = data.values\n",
    "\n",
    "\n",
    "scaler_X = RobustScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "\n",
    "X_tensor = torch.FloatTensor(X_scaled).unsqueeze(1) \n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, model_dim, num_heads, num_encoder_layers, num_decoder_layers, output_dim):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.input_linear = nn.Linear(input_dim, model_dim)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=model_dim,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers\n",
    "        )\n",
    "        self.output_linear = nn.Linear(model_dim, output_dim)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.input_linear(src)\n",
    "        src = src.squeeze(1)\n",
    "        src = src.unsqueeze(0)\n",
    "        output = self.transformer.encoder(src)\n",
    "        output = self.output_linear(output.squeeze(0))\n",
    "        return output\n",
    "\n",
    "model_path = '/Users/gim-yeon-u/Desktop/Sejong Univ/2024-1/캡스톤/elecmodelprotorobustfinal2.pth'\n",
    "model = TransformerModel(input_dim=5, model_dim=128, num_heads=2, num_encoder_layers=2, num_decoder_layers=2, output_dim=1)\n",
    "checkpoint = torch.load(model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = model(X_tensor)\n",
    "\n",
    "predicted_values = prediction.cpu().numpy()\n",
    "\n",
    "print(\"Predicted Values:\", predicted_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gim-yeon-u/miniforge3/envs/tf25/lib/python3.8/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 0.1807, Validation Loss: 0.1713\n",
      "Epoch 2, Training Loss: 0.1728, Validation Loss: 0.1714\n",
      "Epoch 3, Training Loss: 0.1707, Validation Loss: 0.1656\n",
      "Epoch 4, Training Loss: 0.1685, Validation Loss: 0.1632\n",
      "Epoch 5, Training Loss: 0.1665, Validation Loss: 0.1600\n",
      "Epoch 6, Training Loss: 0.1648, Validation Loss: 0.1600\n",
      "Epoch 7, Training Loss: 0.1639, Validation Loss: 0.1606\n",
      "Epoch 8, Training Loss: 0.1630, Validation Loss: 0.1574\n",
      "Epoch 9, Training Loss: 0.1622, Validation Loss: 0.1571\n",
      "Epoch 10, Training Loss: 0.1616, Validation Loss: 0.1586\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, model_dim, num_heads, num_encoder_layers, num_decoder_layers, output_dim):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.input_linear = nn.Linear(input_dim, model_dim)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=model_dim,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers\n",
    "        )\n",
    "        self.output_linear = nn.Linear(model_dim, output_dim)\n",
    "    \n",
    "    def forward(self, src):\n",
    "        src = src.unsqueeze(1)\n",
    "        src = self.input_linear(src)\n",
    "        src = src.permute(1, 0, 2)\n",
    "        output = self.transformer.encoder(src)\n",
    "        output = self.output_linear(output.permute(1, 0, 2).squeeze(1))\n",
    "        return output\n",
    "\n",
    "model_path = '/Users/gim-yeon-u/Desktop/Sejong Univ/2024-1/캡스톤/elecmodelprotorobustfinal2.pth'\n",
    "model = TransformerModel(input_dim=5, model_dim=128, num_heads=2, num_encoder_layers=2, num_decoder_layers=2, output_dim=1)\n",
    "checkpoint = torch.load(model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "data_path = '/Users/gim-yeon-u/Desktop/Sejong Univ/2024-1/캡스톤/elecdummy3.xlsx'\n",
    "data = pd.read_excel(data_path) \n",
    "target = 'Electricity_Usage_kWh'\n",
    "X = data.drop(target, axis=1).values\n",
    "y = data[target].values.reshape(-1, 1)\n",
    "\n",
    "scaler_X = RobustScaler()\n",
    "scaler_y = RobustScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.FloatTensor(y_test)\n",
    "\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
    "criterion = nn.SmoothL1Loss()\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch_x)\n",
    "        loss = criterion(predictions, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_predictions = model(X_test_tensor)\n",
    "        val_loss = criterion(val_predictions, y_test_tensor)\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Training Loss: {avg_loss:.4f}, Validation Loss: {val_loss.item():.4f}')\n",
    "\n",
    "torch.save({'model_state_dict': model.state_dict()}, 'fine_tuned_model_elec_final.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gim-yeon-u/miniforge3/envs/tf25/lib/python3.8/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Values: [[17.391598 ]\n",
      " [17.390575 ]\n",
      " [17.389557 ]\n",
      " ...\n",
      " [ 6.5350723]\n",
      " [ 6.535635 ]\n",
      " [ 6.5362053]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import dump, load\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, model_dim, num_heads, num_encoder_layers, num_decoder_layers, output_dim):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.input_linear = nn.Linear(input_dim, model_dim)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=model_dim,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers\n",
    "        )\n",
    "        self.output_linear = nn.Linear(model_dim, output_dim)\n",
    "    \n",
    "    def forward(self, src):\n",
    "        src = self.input_linear(src)\n",
    "        src = src.permute(1, 0, 2)  \n",
    "        output = self.transformer.encoder(src)\n",
    "        output = self.output_linear(output.permute(1, 0, 2).squeeze(1))\n",
    "        return output\n",
    "\n",
    "train_data_path = '/Users/gim-yeon-u/Desktop/Sejong Univ/2024-1/캡스톤/elecdummy3.xlsx'\n",
    "train_data = pd.read_excel(train_data_path)\n",
    "X_train = train_data.drop('Electricity_Usage_kWh', axis=1).values\n",
    "y_train = train_data['Electricity_Usage_kWh'].values.reshape(-1, 1)\n",
    "\n",
    "scaler_X = RobustScaler()\n",
    "scaler_y = RobustScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "\n",
    "dump(scaler_X, 'scaler_X.joblib')\n",
    "dump(scaler_y, 'scaler_y.joblib')\n",
    "\n",
    "\n",
    "model_path = '/Users/gim-yeon-u/Desktop/Sejong Univ/2024-1/캡스톤/fine_tuned_model_elec_final.pth'\n",
    "model = TransformerModel(input_dim=5, model_dim=128, num_heads=2, num_encoder_layers=2, num_decoder_layers=2, output_dim=1)\n",
    "checkpoint = torch.load(model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "predict_data_path = '/Users/gim-yeon-u/Desktop/Sejong Univ/2024-1/캡스톤/elec5.xlsx'\n",
    "predict_data = pd.read_excel(predict_data_path)\n",
    "X_predict = predict_data.values\n",
    "\n",
    "scaler_X = load('scaler_X.joblib')\n",
    "X_predict_scaled = scaler_X.transform(X_predict)\n",
    "X_predict_tensor = torch.FloatTensor(X_predict_scaled).unsqueeze(1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction_tensor = model(X_predict_tensor)\n",
    "    prediction = prediction_tensor.cpu().numpy()\n",
    "\n",
    "scaler_y = load('scaler_y.joblib')\n",
    "predicted_values_rescaled = scaler_y.inverse_transform(prediction)\n",
    "\n",
    "print(\"Predicted Values:\", predicted_values_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gim-yeon-u/miniforge3/envs/tf25/lib/python3.8/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Values: [[56.982906]\n",
      " [57.003807]\n",
      " [57.024197]\n",
      " ...\n",
      " [10.696982]\n",
      " [10.702027]\n",
      " [10.707076]]\n"
     ]
    }
   ],
   "source": [
    "model_path = '/Users/gim-yeon-u/Desktop/Sejong Univ/2024-1/캡스톤/fine_tuned_model_elec_final.pth'\n",
    "model = TransformerModel(input_dim=5, model_dim=128, num_heads=2, num_encoder_layers=2, num_decoder_layers=2, output_dim=1)\n",
    "checkpoint = torch.load(model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "predict_data_path = '/Users/gim-yeon-u/Desktop/Sejong Univ/2024-1/캡스톤/elec5.xlsx'\n",
    "predict_data = pd.read_excel(predict_data_path)\n",
    "X_predict = predict_data.values\n",
    "\n",
    "scaler_X = load('scaler_X.joblib')\n",
    "X_predict_scaled = scaler_X.transform(X_predict)\n",
    "X_predict_tensor = torch.FloatTensor(X_predict_scaled).unsqueeze(1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction_tensor = model(X_predict_tensor)\n",
    "    prediction = prediction_tensor.cpu().numpy()\n",
    "\n",
    "scaler_y = load('scaler_y.joblib')\n",
    "predicted_values_rescaled = scaler_y.inverse_transform(prediction)\n",
    "\n",
    "print(\"Predicted Values:\", predicted_values_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = pd.DataFrame(predicted_values_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.to_csv('elecresultfinal2.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
